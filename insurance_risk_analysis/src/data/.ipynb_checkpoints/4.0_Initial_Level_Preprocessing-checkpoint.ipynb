{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = os.path.abspath(os.path.join(os.getcwd(),os.path.pardir,os.path.pardir,'data','raw'))\n",
    "INTERIM_DATA_PATH = os.path.abspath(os.path.join(os.getcwd(),os.path.pardir,os.path.pardir,'data','interim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsample = SMOTE(sampling_strategy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,kind='train'):\n",
    "    # Droppin ID and Gender\n",
    "    df = df.drop(['ID','Gender','Unnamed: 0','flag'],axis = 1)\n",
    "    \n",
    "    # Label encoding for Agency type, distribution channel\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    df['Agency Type'] = label_encoder.fit_transform(df['Agency Type']) \n",
    "    df['Distribution Channel'] = label_encoder.fit_transform(df['Distribution Channel']) \n",
    "    \n",
    "    \n",
    "    # replacing negative duration by median\n",
    "    if kind=='train':\n",
    "        df[\"Duration\"] = np.where(df[\"Duration\"] < 0, df.Duration.median(), df['Duration'])\n",
    "        imputations =  {\n",
    "            'column' : ['Duration'],\n",
    "            'values' : [df.Duration.median()]\n",
    "        }\n",
    "        imputations = pd.DataFrame(imputations)\n",
    "        imputations.to_csv(os.path.join(INTERIM_DATA_PATH,'imputations.csv'))\n",
    "    else:\n",
    "        imputations = pd.read_csv(os.path.join(INTERIM_DATA_PATH,'imputations.csv'))\n",
    "        imputation = imputations[imputations['column']=='Duration']['values'][0]\n",
    "        df[\"Duration\"] = np.where(df[\"Duration\"] < 0, imputation, df['Duration'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scale values\n",
    "    scaled_features = preprocessing.StandardScaler().fit_transform(df[['Net Sales','Commision (in value)','Age']])\n",
    "    scaled_features = pd.DataFrame(scaled_features, index=df.index, columns=['Net Sales','Commision (in value)','Age'])\n",
    "    df['Net Sales'] = scaled_features['Net Sales']\n",
    "    df['Commision (in value)'] = scaled_features['Commision (in value)']\n",
    "    df['Age'] = scaled_features['Age']\n",
    "    \n",
    "    \n",
    "    if kind=='train':\n",
    "        X = df.drop('Claim',axis=1)\n",
    "        y = df['Claim']\n",
    "\n",
    "        X_res, y_res = rsample.fit_resample(X,y)\n",
    "        X_res = pd.DataFrame(X_res, columns = X.columns)\n",
    "        y_res = pd.DataFrame(y_res, columns = ['Claim'])\n",
    "        X_res['Claim'] = y_res['Claim']\n",
    "        df = X_res\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dummies(df_train,df_test,df_val):\n",
    "    df_train['flag']=1\n",
    "    df_test['flag']=0\n",
    "    df_val['flag']=2\n",
    "    combined = pd.concat([df_train,df_test,df_val])\n",
    "    combined = pd.get_dummies(data=combined, columns=['Product Name', 'Destination','Agency'])\n",
    "    df_train=combined[combined['flag']==1]\n",
    "    df_test = combined[combined['flag']==0]\n",
    "    df_val = combined[combined['flag']==2]\n",
    "    return df_train,df_test,df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(RAW_DATA_PATH,'train_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(RAW_DATA_PATH,'test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(os.path.join(RAW_DATA_PATH,'val_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_val = calculate_dummies(df_train,df_test,df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "df_train = process_data(df_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "df_test = process_data(df_test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "df_val = process_data(df_val,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(os.path.join(INTERIM_DATA_PATH,'test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(INTERIM_DATA_PATH,'train_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_csv(os.path.join(INTERIM_DATA_PATH,'val_set.csv')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
